lang_code: "English (US)"
app_ttl: "DiffTrainer"
tab_ttl_1: "About"
tab_ttl_2: "Data Preparation"
tab_ttl_3: "Configuration"
tab_ttl_4: "Preprocess&Train"
tab_ttl_5: "Export Singer(basic)"
tab_ttl_6: "Export Singer(advanced)"

# About tab
vers: "version"
install: "Full install" #no longer used, can skip
install2: "Installs DiffSinger, Uta's Converter, SOME, and all Python requirements.\n Running this a second time will delete and replace all files." #no longer used, can skip
changelog: "View changelog"
update: "Update tools"
update2: "Installs DiffSinger, Uta's Converter, SOME, but not the Python requirements.\n Running this a second time will delete and replace all files."
cred_lead: "Maintainer:"
cred_tools: "Additional credits"
cred_front: "Front end:"
cred_back: "Back end:"
cred_trans: "Translation: N/A"
restart: "(restart to apply)"
#note: string should not be longer than this or it will be cut off

#Data Prep tab
silperseg: "Max no. of silences per segment"
silperseg2: "How many instances of AP/SP will be allowed in a single segment.\nThe next silence will start a new segment."
length_sil: "Max length of silences(seconds)"
length_sil2: "How long each silence is allowed to be.\nLonger silences will be split.\nThis is not an exact value, and may be shorter or longer if needed."
length_seg: "Max length of segments(seconds)"
length_seg2: "How long each segment is allowed to be. Longer segments will be split.\nThis is not an exact value, and may be shorter or longer if needed.\nRecommended value: At least 5, but very weak GPUs may only be able to handle 2-4. 1 is not recommended."
estmidi: "Estimate MIDI:"
estmidiA: "Default method"
estmidiA2: "Uses Parselmouth to calculate pitch. Low accuracy, but lightweight."
estmidiB: "SOME"
estmidiB2: "Uses SOME to calculate pitch. High accuracy, but requires more processing power."
estmidiC: "Off"
estmidi2: "Calculates pitch of each phoneme. Required to train a pitch model."
estmidi2A: "Lightweight, but often inaccurate results."
estmidi2B: "Much more accurate, but more resource-heavy."
detbre: "Detect breath"
detbre2: "Tries to account for the sounds of breathing in segments. Inconsistent results."
rawdata: "Select raw data folder"
rawdata2: "Must be located in raw_data. This should be one folder for the whole model, \nwith subfolders for each speaker containing both .wav and .lab files."
prepdata: "Prepare data"
prepdata2: "Run the process to prepare the data in Diffsinger format."

#Config tab
type: "Type:"
aco: "Acoustic"
var: "Variance"
adv: "ADVANCED: Custom config"
adv2: "Unlocks options to individually select parameters. \nOnly recommended for experienced users."
datafolder: "Select formatted data folder"
datafolder2: "Select a folder that has been processed on the previous tab. \nCan be located anywhere, but a subfolder of /diffsinger/data is recommended."
savefolder: "Select checkpoint save folder"
savefolder2: "Select where your checkpoints will be saved. Must be a subfolder of /diffsinger/checkpoints."
confsel: "Select configuration:"
confsel2: "Select from this list of preset configurations.\n All options have been tested."
advconfig: "Advanced configuration:"
advconfig2: "Select individual options for the configuration.\n Non-functional combinations are possible."
dummy: "This is a placeholder, not a real option."
vr: "VR preprocessing"
vr2: "Can produce more accurate variance results, but requires high processing power. \n Only recommended for GPU users."
wavenet: "alt. backbone"
wavenet2: "Reverts acoustic to the previous wavenet default, or enables lynxnet for variance."
speaker: "Speaker"
spk_lang: "Language"
spk_lang2: "The primary language of the speaker."
other: "Other language"
spk_id: "ID"
spk_id2: "All speakers with the same number will export as a single, merged speaker.\nRecommended for multiple languages from the same voice."
lang_edit: "Edit language settings"
lang_edit2: "Configure which dictionaries are imported, global phonemes, and merged phonemes."
saveint: "Save interval:"
saveint2: "The checkpoint will save every f'{saveint}' steps."
maxbatch: "Max batch size"
maxbatch2: "How many files the training will process at once.\nRecommended values vary heavily by system, but try starting with 9 for acoustic and 24 for variance.\nThis value can be changed without reprocessing the binaries."
saveconf: "Save configuration"
sampleerror: "Not enough samples in" #as in not enough samples in spk_name

dicts: "Dictionaries:"
dicts2: "Make sure to list only the dictionaries for languages being used. \nSelect a dictionary to remove by clicking the line to highlight it."
add_dict: "Add dictionary"
del_dict: "Remove dictionary"
ext_ph: "Extra phonemes:"
ext_ph2: "List all global phonemes with no prefix, or additional language-specific phonemes with their prefix. \nSeparate phonemes with commas, spaces are optional."
merge: "Merge list location:"
merge2: "Writing your own merged phoneme list is extremely recommended. \nThe default list provided should mostly be taken as a reference for formatting. \nThis file must be located in the dictionaries folder."
langsave: "Save and return to configuration"

#Train tab
step1: "Select configuration"
step1-2: "Select a configuration that has been set up for the correct dataset."
step2: "Select checkpoint folder"
step2-2: "Select the folder where checkpoints will be saved.\nThis should match the one in the configuration."
step3a: "Preprocess data"
step3a2: "Prepares binarized data for the training process.\nRun this once per configuration."
step3b: "Train"
warning1: "This window will not respond during training."
warning2: "To stop training, press Ctrl+C in the command line window."
patchlabel: "Optional patch:"
patchbutton: "Use Tensor cores"
patchtip: "For more recent Nvidia GPUs.\nIf you get a message about using tensor cores at the beginning of training, this patch may improve performance slightly."

#Export tab
##strings 'aco', 'var', and 'step2' are reused
acotip: "Exports an acoustic checkpoint to ONNX."
vartip: "Exports a variance checkpoint to ONNX."
step2-2alt: "Select the folder where checkpoints have been saved.\nThe most recent checkpoint in the folder will be used."
onnx: "Export ONNX"
oupatch: "Temporary patch button(run once after setup/update)"
namebox: "Enter the name of your singer with no spaces or special characters."
getaco: "Select acoustic checkpoint folder"
getaco2: "This should be the same folder used for saving checkpoints, NOT the onnx folder."
getvar: "Select variance checkpoint folder"
dur: "Duration"
pit: "Pitch"
ousave: "Select save location"
ousave2: "Select where the final singer folder will be saved.\nIt is recommended to save directly into your OpenUTAU/singers folder."
vocoder: "OPTIONAL: Custom vocoder"
vocoder_adv: "Vocoder ONNX"
vocoder2: "If the model has a non-default vocoder, select the ONNX file here."
ouexport: "Prepare for OpenUtau"

#Quick Inference
##strings 'getaco' and 'getvar' are reused
getds: "Select .ds file"
eval: "Evaluating .ds file..."
hasdur: "Existing duration data detected"
haspitch: "Existing pitch data detected"
hasbre: "Existing breathiness data detected"
hasene: "Existing energy data detected"
hasten: "Existing tension data detected"
hasvoc: "Existing voicing data detected"
eval2: ".ds file evaluated!"
varckpt: "Variance ckpt folder"
acockpt: "Acoustic ckpt folder"
overwrite: "Overwrite existing parameters:"
spk: "enter speaker name"
langcode: "main language code"
inf1: "Inferencing variance data..."
inf2: "Inferencing acoustic data..."
render: "Render audio"
replay: "Replay rendered audio"
replayerror: "Error replaying rendered audio"


#test
testingline: "testtesttest"